{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Scrapping data dengan Youtube API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Komentar\n",
      "1          Dosen ketemu pertanyaan y jawabanny bagus,.\n",
      "2    Coba perhatikan Anies, bukan senyum melaikan A...\n",
      "3    Waktu kemarin debat pertama menurut saya pak A...\n",
      "4    Nilai debat kemarin \\nPaslon 1 = 120\\nPaslom 2...\n",
      "5    Suka banget lihat percakapan dan bahasa tubuh ...\n",
      "..                                                 ...\n",
      "371  Jawaban PRABOWO jelas sesuai pngalaman Beliau ...\n",
      "372  bayi jg jdi pemimpin...asal ayah presiden kano...\n",
      "373                                            ttep 02\n",
      "374  jagoan lu no 2 levelnya rendah jadi kasih pert...\n",
      "375  prabowo kebanyakan kata-kata saudara-saudara s...\n",
      "\n",
      "[375 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# web scraping\n",
    "import pandas as pd\n",
    "import os\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "os.environ['OAUTHLIB_INSECURE_TRANSPORT'] = '1'\n",
    "youTubeApiKey = 'AIzaSyACM3jJ5dy3rTBWYzR8hBvI_OTP4FoBoXo'\n",
    "youtube = build('youtube', 'v3', developerKey=youTubeApiKey)\n",
    "data_video = [[\"Nama\", \"Komentar\", \"Waktu\", \"Likes\", \"Reply Count\"]]\n",
    "\n",
    "def get_all_comment(video_use):\n",
    "    param_comment = youtube.commentThreads().list(part=\"snippet\", videoId=video_use, maxResults=\"100\", textFormat=\"plainText\")\n",
    "    \n",
    "    while True:\n",
    "        data_comment = param_comment.execute()\n",
    "\n",
    "        for i in data_comment[\"items\"]:\n",
    "            name = i[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"authorDisplayName\"]\n",
    "            comment = i[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"textDisplay\"]\n",
    "            published_at = i[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"publishedAt\"]\n",
    "            likes = i[\"snippet\"][\"topLevelComment\"][\"snippet\"][\"likeCount\"]\n",
    "            replies = i[\"snippet\"][\"totalReplyCount\"]\n",
    "            data_video.append([name, comment, published_at, likes, replies])\n",
    "\n",
    "            totalReplyCount = i[\"snippet\"][\"totalReplyCount\"]\n",
    "            if totalReplyCount > 0:\n",
    "                parent = i[\"snippet\"][\"topLevelComment\"][\"id\"]\n",
    "                param_replies = youtube.comments().list(part=\"snippet\", maxResults=\"100\", parentId=parent, textFormat=\"plainText\")\n",
    "                data_replies = param_replies.execute()\n",
    "                for reply in data_replies[\"items\"]:\n",
    "                    reply_name = reply[\"snippet\"][\"authorDisplayName\"]\n",
    "                    reply_comment = reply[\"snippet\"][\"textDisplay\"]\n",
    "                    reply_published_at = reply[\"snippet\"][\"publishedAt\"]\n",
    "                    reply_likes = reply[\"snippet\"][\"likeCount\"]\n",
    "                    reply_replies = \"\"\n",
    "                    data_video.append([reply_name, reply_comment, reply_published_at, reply_likes, reply_replies])\n",
    "\n",
    "        if 'nextPageToken' in data_comment:\n",
    "            nextToken = data_comment['nextPageToken']\n",
    "            param_comment = youtube.commentThreads().list(part=\"snippet\", videoId=video_use, maxResults=\"100\", textFormat=\"plainText\", pageToken=nextToken)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "get_all_comment(\"qtBuBYBsnTw\")\n",
    "df = pd.DataFrame({\"Nama\": [i[0] for i in data_video], \n",
    "                   \"Komentar\": [i[1] for i in data_video], \n",
    "                   \"Waktu\": [i[2] for i in data_video],\n",
    "                   \"Likes\": [i[3] for i in data_video], \n",
    "                   \"Reply Count\": [i[4] for i in data_video]}\n",
    "                 )\n",
    "df.to_csv(\"Hasil Scrape.csv\", index=False, header=False)\n",
    "\n",
    "df_data = pd.DataFrame({\"Nama\": [i[0] for i in data_video], \n",
    "                        \"Komentar\": [i[1] for i in data_video], \n",
    "                        \"Waktu\": [i[2] for i in data_video]}\n",
    "                      )\n",
    "df_show = df_data.copy()\n",
    "df_show = df_show.drop(0)\n",
    "df = df_data.drop(['Nama', 'Waktu'], axis=1)\n",
    "df = df.drop(0)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Text Preprocessing\n",
    "<h3> 1. Case Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# # MENGUBAH TEXT MENJADI LOWERCASE\n",
    "# df['Komentar'] = df['Komentar'].str.lower()\n",
    "# df['Komentar'] = df['Komentar'].str.strip()\n",
    "# # MENGHAPUS ANGKA\n",
    "# df['Komentar'] = df['Komentar'].apply(lambda x: re.sub(r'\\d', '', x))\n",
    "# # MENGHAPUS TANDA BACA\n",
    "# df['Komentar'] = df['Komentar'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "# df['Komentar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1               Dosen ketemu pertanyaan  jawabanny bagus\n",
       "2      Coba perhatikan Anies bukan senyum melaikan An...\n",
       "3      Waktu kemarin debat pertama menurut saya pak A...\n",
       "4      Nilai debat kemarin Paslon Paslom Paslon Ini n...\n",
       "5      Suka banget lihat percakapan dan bahasa tubuh ...\n",
       "                             ...                        \n",
       "371    Jawaban PRABOWO jelas sesuai pngalaman Beliau ...\n",
       "372        bayi jg jdi pemimpinasal ayah presiden kanoha\n",
       "373                                                 ttep\n",
       "374    jagoan lu no levelnya rendah jadi kasih pertan...\n",
       "375    prabowo kebanyakan katakata saudarasaudara sek...\n",
       "Name: Komentar, Length: 375, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# remove non ASCII character\n",
    "def remove_non_ASCII(text):\n",
    "    return text.encode('ascii', 'replace').decode('ascii')\n",
    "\n",
    "df['Komentar'] = df['Komentar'].apply(remove_non_ASCII)\n",
    "\n",
    "# remove number\n",
    "def remove_number(text):\n",
    "    return re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "df['Komentar'] = df['Komentar'].apply(remove_number)\n",
    "\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "df['Komentar'] = df['Komentar'].apply(remove_punctuation)\n",
    "\n",
    "# remove whitespace leading & trailing\n",
    "def remove_whitespace_LT(text):\n",
    "    return text.strip()\n",
    "\n",
    "df['Komentar'] = df['Komentar'].apply(remove_whitespace_LT)\n",
    "\n",
    "# remove multiple whitespace into single whitespace\n",
    "def remove_whitespace_multiple(text):\n",
    "    return re.sub('\\s+', ' ', text)\n",
    "\n",
    "df['Komentar'] = df['Komentar'].apply(remove_whitespace_multiple)\n",
    "\n",
    "# remove single char\n",
    "def remove_single_char(text):\n",
    "    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "\n",
    "df['Komentar'] = df['Komentar'].apply(remove_single_char)\n",
    "df['Komentar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing Result : \n",
      "\n",
      "1        [Dosen, ketemu, pertanyaan, jawabanny, bagus]\n",
      "2    [Coba, perhatikan, Anies, bukan, senyum, melai...\n",
      "3    [Waktu, kemarin, debat, pertama, menurut, saya...\n",
      "4    [Nilai, debat, kemarin, Paslon, Paslom, Paslon...\n",
      "5    [Suka, banget, lihat, percakapan, dan, bahasa,...\n",
      "Name: komentar_tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import word_tokenize & FreqDist from NLTK\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.probability import FreqDist\n",
    "# NLTK word rokenize \n",
    "def word_tokenize_wrapper(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "df['komentar_tokens'] = df['Komentar'].apply(word_tokenize_wrapper)\n",
    "\n",
    "print('Tokenizing Result : \\n') \n",
    "print(df['komentar_tokens'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                    [Dosen, ketemu, jawabanny, bagus]\n",
      "2    [Coba, perhatikan, Anies, senyum, melaikan, An...\n",
      "3    [Waktu, kemarin, debat, Anies, bagus, Tapi, ka...\n",
      "4    [Nilai, debat, kemarin, Paslon, Paslom, Paslon...\n",
      "5    [Suka, banget, lihat, percakapan, bahasa, tubu...\n",
      "Name: komentar_tokens_WSW, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# ----------------------- get stopword from NLTK stopword -------------------------------\n",
    "# get stopword indonesia\n",
    "list_stopwords = stopwords.words('indonesian')\n",
    "\n",
    "\n",
    "# ---------------------------- manualy add stopword  ------------------------------------\n",
    "# append additional stopword\n",
    "list_stopwords.extend([\"yg\", \"dg\", \"rt\", \"dgn\", \"ny\", \"d\", 'klo', \n",
    "                       'kalo', 'amp', 'biar', 'bikin', 'bilang', \n",
    "                       'gak', 'ga', 'krn', 'nya', 'nih', 'sih', \n",
    "                       'si', 'tau', 'tdk', 'tuh', 'utk', 'ya', \n",
    "                       'jd', 'jgn', 'sdh', 'aja', 'n', 't', \n",
    "                       'nyg', 'hehe', 'pen', 'u', 'nan', 'loh', 'rt',\n",
    "                       '&amp', 'yah'])\n",
    "\n",
    "# ----------------------- add stopword from txt file ------------------------------------\n",
    "# read txt stopword using pandas\n",
    "# txt_stopword = pd.read_csv(\"stopwords.txt\", names= [\"stopwords\"], header = None)\n",
    "\n",
    "# # convert stopword string to list & append additional stopword\n",
    "# list_stopwords.extend(txt_stopword[\"stopwords\"][0].split(' '))\n",
    "\n",
    "# ---------------------------------------------------------------------------------------\n",
    "\n",
    "# convert list to dictionary\n",
    "list_stopwords = set(list_stopwords)\n",
    "\n",
    "\n",
    "#remove stopword pada list token\n",
    "def stopwords_removal(words):\n",
    "    return [word for word in words if word not in list_stopwords]\n",
    "\n",
    "df['komentar_tokens_WSW'] = df['komentar_tokens'].apply(stopwords_removal) \n",
    "\n",
    "\n",
    "print(df['komentar_tokens_WSW'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Sebelum Penghapusan Baris Kosong:\n",
      "                                              Komentar  \\\n",
      "1             Dosen ketemu pertanyaan  jawabanny bagus   \n",
      "2    Coba perhatikan Anies bukan senyum melaikan An...   \n",
      "3    Waktu kemarin debat pertama menurut saya pak A...   \n",
      "4    Nilai debat kemarin Paslon Paslom Paslon Ini n...   \n",
      "5    Suka banget lihat percakapan dan bahasa tubuh ...   \n",
      "..                                                 ...   \n",
      "371  Jawaban PRABOWO jelas sesuai pngalaman Beliau ...   \n",
      "372      bayi jg jdi pemimpinasal ayah presiden kanoha   \n",
      "373                                               ttep   \n",
      "374  jagoan lu no levelnya rendah jadi kasih pertan...   \n",
      "375  prabowo kebanyakan katakata saudarasaudara sek...   \n",
      "\n",
      "                                       komentar_tokens  \\\n",
      "1        [Dosen, ketemu, pertanyaan, jawabanny, bagus]   \n",
      "2    [Coba, perhatikan, Anies, bukan, senyum, melai...   \n",
      "3    [Waktu, kemarin, debat, pertama, menurut, saya...   \n",
      "4    [Nilai, debat, kemarin, Paslon, Paslom, Paslon...   \n",
      "5    [Suka, banget, lihat, percakapan, dan, bahasa,...   \n",
      "..                                                 ...   \n",
      "371  [Jawaban, PRABOWO, jelas, sesuai, pngalaman, B...   \n",
      "372  [bayi, jg, jdi, pemimpinasal, ayah, presiden, ...   \n",
      "373                                             [ttep]   \n",
      "374  [jagoan, lu, no, levelnya, rendah, jadi, kasih...   \n",
      "375  [prabowo, kebanyakan, katakata, saudarasaudara...   \n",
      "\n",
      "                                   komentar_tokens_WSW  \n",
      "1                    [Dosen, ketemu, jawabanny, bagus]  \n",
      "2    [Coba, perhatikan, Anies, senyum, melaikan, An...  \n",
      "3    [Waktu, kemarin, debat, Anies, bagus, Tapi, ka...  \n",
      "4    [Nilai, debat, kemarin, Paslon, Paslom, Paslon...  \n",
      "5    [Suka, banget, lihat, percakapan, bahasa, tubu...  \n",
      "..                                                 ...  \n",
      "371  [Jawaban, PRABOWO, sesuai, pngalaman, Beliau, ...  \n",
      "372  [bayi, jg, jdi, pemimpinasal, ayah, presiden, ...  \n",
      "373                                             [ttep]  \n",
      "374  [jagoan, lu, no, levelnya, rendah, kasih, etik...  \n",
      "375  [prabowo, kebanyakan, katakata, saudarasaudara...  \n",
      "\n",
      "[375 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of                                               Komentar  \\\n",
       "1             Dosen ketemu pertanyaan  jawabanny bagus   \n",
       "2    Coba perhatikan Anies bukan senyum melaikan An...   \n",
       "3    Waktu kemarin debat pertama menurut saya pak A...   \n",
       "4    Nilai debat kemarin Paslon Paslom Paslon Ini n...   \n",
       "5    Suka banget lihat percakapan dan bahasa tubuh ...   \n",
       "..                                                 ...   \n",
       "371  Jawaban PRABOWO jelas sesuai pngalaman Beliau ...   \n",
       "372      bayi jg jdi pemimpinasal ayah presiden kanoha   \n",
       "373                                               ttep   \n",
       "374  jagoan lu no levelnya rendah jadi kasih pertan...   \n",
       "375  prabowo kebanyakan katakata saudarasaudara sek...   \n",
       "\n",
       "                                       komentar_tokens  \\\n",
       "1        [Dosen, ketemu, pertanyaan, jawabanny, bagus]   \n",
       "2    [Coba, perhatikan, Anies, bukan, senyum, melai...   \n",
       "3    [Waktu, kemarin, debat, pertama, menurut, saya...   \n",
       "4    [Nilai, debat, kemarin, Paslon, Paslom, Paslon...   \n",
       "5    [Suka, banget, lihat, percakapan, dan, bahasa,...   \n",
       "..                                                 ...   \n",
       "371  [Jawaban, PRABOWO, jelas, sesuai, pngalaman, B...   \n",
       "372  [bayi, jg, jdi, pemimpinasal, ayah, presiden, ...   \n",
       "373                                             [ttep]   \n",
       "374  [jagoan, lu, no, levelnya, rendah, jadi, kasih...   \n",
       "375  [prabowo, kebanyakan, katakata, saudarasaudara...   \n",
       "\n",
       "                                   komentar_tokens_WSW  \n",
       "1                    [Dosen, ketemu, jawabanny, bagus]  \n",
       "2    [Coba, perhatikan, Anies, senyum, melaikan, An...  \n",
       "3    [Waktu, kemarin, debat, Anies, bagus, Tapi, ka...  \n",
       "4    [Nilai, debat, kemarin, Paslon, Paslom, Paslon...  \n",
       "5    [Suka, banget, lihat, percakapan, bahasa, tubu...  \n",
       "..                                                 ...  \n",
       "371  [Jawaban, PRABOWO, sesuai, pngalaman, Beliau, ...  \n",
       "372  [bayi, jg, jdi, pemimpinasal, ayah, presiden, ...  \n",
       "373                                             [ttep]  \n",
       "374  [jagoan, lu, no, levelnya, rendah, kasih, etik...  \n",
       "375  [prabowo, kebanyakan, katakata, saudarasaudara...  \n",
       "\n",
       "[357 rows x 3 columns]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gantikan nilai kosong dengan NaN\n",
    "df.replace('', pd.NA, inplace=True)\n",
    "\n",
    "# Menampilkan DataFrame sebelum penghapusan\n",
    "print(\"DataFrame Sebelum Penghapusan Baris Kosong:\")\n",
    "print(df)\n",
    "\n",
    "# Menghapus baris yang memiliki nilai NaN\n",
    "df = df.dropna()\n",
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"Text_Preprocessing_2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizad_word = pd.read_excel(\"normalisasi.xlsx\")\n",
    "\n",
    "# normalizad_word_dict = {}\n",
    "\n",
    "# for index, row in normalizad_word.iterrows():\n",
    "#     if row[0] not in normalizad_word_dict:\n",
    "#         normalizad_word_dict[row[0]] = row[1] \n",
    "\n",
    "# def normalized_term(document):\n",
    "#     return [normalizad_word_dict[term] if term in normalizad_word_dict else term for term in document]\n",
    "\n",
    "# df['tweet_normalized'] = df['komentar_tokens_WSW'].apply(normalized_term)\n",
    "\n",
    "# df['tweet_normalized'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Stemming\n",
    "\n",
    "# # import Sastrawi package\n",
    "# from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "# import swifter\n",
    "\n",
    "\n",
    "# # create stemmer\n",
    "# factory = StemmerFactory()\n",
    "# stemmer = factory.create_stemmer()\n",
    "\n",
    "# # stemmed\n",
    "# def stemmed_wrapper(term):\n",
    "#     return stemmer.stem(term)\n",
    "\n",
    "# term_dict = {}\n",
    "\n",
    "# for document in df['komentar_tokens_WSW']:\n",
    "#     for term in document:\n",
    "#         if term not in term_dict:\n",
    "#             term_dict[term] = ' '\n",
    "            \n",
    "# print(len(term_dict))\n",
    "# print(\"------------------------\")\n",
    "\n",
    "# for term in term_dict:\n",
    "#     term_dict[term] = stemmed_wrapper(term)\n",
    "#     print(term,\":\" ,term_dict[term])\n",
    "    \n",
    "# print(term_dict)\n",
    "# print(\"------------------------\")\n",
    "\n",
    "\n",
    "# # apply stemmed term to dataframe\n",
    "# def get_stemmed_term(document):\n",
    "#     return [term_dict[term] for term in document]\n",
    "\n",
    "# df['komentar_tokens_stemmed'] = df['komentar_tokens_WSW'].swifter.apply(get_stemmed_term)\n",
    "# print(df['komentar_tokens_stemmed'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
